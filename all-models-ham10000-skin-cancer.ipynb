{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport matplotlib.image as img\nimport PIL\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom PIL import Image\nimport random \nfrom tensorflow.keras.models import Sequential , Model\nfrom tensorflow.keras.layers import Input , MaxPool2D , Conv2D , Flatten , Dense , Dropout \nfrom tensorflow.keras import optimizers \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3 \nfrom tensorflow.keras.applications.densenet import DenseNet201\nfrom tensorflow.keras.applications.vgg16 import VGG16 \nfrom tensorflow.keras.applications.xception import Xception \nfrom tensorflow.keras.applications.nasnet import NASNetMobile\nfrom tensorflow.keras.applications.vgg19 import VGG19 \nfrom glob import glob \nimport pathlib \nimport os \nfrom sklearn.preprocessing import LabelEncoder  \nfrom sklearn.utils import resample  \nfrom keras.utils import to_categorical  \nfrom sklearn.model_selection import train_test_split \nnp.random.seed(101)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading the data from the csv file \nskin_df = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\n\n#getting the image path for the images using the csv \nimage_path = {os.path.splitext(os.path.basename(x))[0]: x for x in glob(os.path.join('/kaggle/input/skin-cancer-mnist-ham10000/', '*', '*.jpg'))}\n\n# adding the images to the path obtained above \nskin_df['path'] = skin_df['image_id'].map(image_path.get)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using the above image path in order to add the images to the dataframe \n# via numpy reshape\nskin_df['image'] = skin_df['path'].map(lambda x: np.asarray(Image.open(x).resize((128,128))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the first 30 data entries from the csv \nskin_df.head(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using label encoder in order to grab the different classes of images from the \n# dataset and the csv\nle = LabelEncoder()\nle.fit(skin_df['dx'])\nLabelEncoder()\nprint(list(le.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skin_df['label'] = le.transform(skin_df['dx'])\nprint(skin_df.sample(10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting the different relations for exloratory data analysis in the given \n# dataset for understanding the trends :-\nfig = plt.figure(figsize=(15,10))\n\n# Count by Cell Type\nax1 = fig.add_subplot(221)\nskin_df['dx'].value_counts().plot(kind='bar', ax=ax1)\nax1.set_ylabel('Count')\nax1.set_title('Cell Type')\n\n# Count by Sex\nax2 = fig.add_subplot(222)\nskin_df['sex'].value_counts().plot(kind='bar', ax=ax2)\nax2.set_ylabel('Count', size=15)\nax2.set_title('Sex')\n\n# Count by Localization (region)\nax3 = fig.add_subplot(223)\nskin_df['localization'].value_counts().plot(kind='bar')\nax3.set_ylabel('Count', size=12)\nax3.set_title('Localization')\n\n# Count by Age\nax4 = fig.add_subplot(224)\nsample_age = skin_df[pd.notnull(skin_df['age'])]\nsns.distplot(sample_age['age'], color='red')\nax4.set_title('Age')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(skin_df['label'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_0 = skin_df[skin_df['label'] == 0]\ndf_1 = skin_df[skin_df['label'] == 1]\ndf_2 = skin_df[skin_df['label'] == 2]\ndf_3 = skin_df[skin_df['label'] == 3]\ndf_4 = skin_df[skin_df['label'] == 4]\ndf_5 = skin_df[skin_df['label'] == 5]\ndf_6 = skin_df[skin_df['label'] == 6]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resampling 800 samples from each class with replacement in order to \n# balance the imbalanced dataset \n\nn_samples = 800\ndf_0_balanced = resample(df_0, replace=True, n_samples=n_samples, random_state=101)\ndf_1_balanced = resample(df_1, replace=True, n_samples=n_samples, random_state=101)\ndf_2_balanced = resample(df_2, replace=True, n_samples=n_samples, random_state=101)\ndf_3_balanced = resample(df_3, replace=True, n_samples=n_samples, random_state=101)\ndf_4_balanced = resample(df_4, replace=True, n_samples=n_samples, random_state=101)\ndf_5_balanced = resample(df_5, replace=True, n_samples=n_samples, random_state=101)\ndf_6_balanced = resample(df_6, replace=True, n_samples=n_samples, random_state=101)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combining all the above splitted dataframes into a single dataframe for \n# processing. \nskin_df_balanced = pd.concat([df_0_balanced, df_1_balanced, df_2_balanced, df_3_balanced, df_4_balanced, df_5_balanced, df_6_balanced])\nskin_df_balanced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking whether the classes are now balanced :- \nprint(skin_df_balanced['label'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_samples = 5 # number of samples for plotting\n# Plotting\nfig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\nfor n_axs, (type_name, type_rows) in zip(m_axs, \n                                         skin_df_balanced.sort_values(['dx']).groupby('dx')):\n    n_axs[0].set_title(type_name)\n    \n    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n        c_ax.imshow(c_row['image'])\n        c_ax.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshaping the images in order for better processing \nX = np.asarray(skin_df_balanced['image'].tolist())\nX = X/255\nY = skin_df_balanced['label']\nY_cat = to_categorical(Y, num_classes=7)\nY_cat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the train test and validation splits , here the testing splitted data \n# will be used for validation \n\nx_train, x_test, y_train, y_test = train_test_split(X, Y_cat, test_size=0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for the tensor shapes of the images :-\n\nskin_df_balanced['image'].map(lambda x: x.shape).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n'''\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)\n'''\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ALL the models Initiation and Compilation \n\n####\n# INCEPTION_V3 MODEL :-\n####\n\nmod_InceptionV3 = InceptionV3(weights = \"imagenet\" , include_top = False , input_shape = (128 , 128 , 3))\n\nfor layer in mod_InceptionV3.layers:\n    layer.trainable = False\n\n\nx = mod_InceptionV3.output\nx = Flatten()(x)\nx = Dropout(0.35)(x)\nx = Dense(7 , activation = 'softmax')(x)\n\nmodel_InceptionV3 = Model(inputs = mod_InceptionV3.input , outputs = x)\n\nmodel_InceptionV3.compile(loss = tf.keras.losses.CategoricalCrossentropy() , \noptimizer = optimizers.Adam(learning_rate = 0.001) , \nmetrics = ['accuracy'])\n\n\n####\n# Xception MODEL :-\n####\nmod_Xception = Xception(weights = \"imagenet\" , include_top = False , input_shape = (128 , 128 , 3))\nfor layer in mod_Xception.layers:\n    layer.trainable = False\n\nm = mod_Xception.output\nm = Flatten()(m)\nm = Dropout(0.35)(m)\nm = Dense(7 , activation = 'softmax')(m)\n\nmodel_Xception = Model(inputs = mod_Xception.input , outputs = m)\n\nmodel_Xception.compile(loss = tf.keras.losses.CategoricalCrossentropy() , \noptimizer = optimizers.Adam(learning_rate = 0.001) , \nmetrics = ['accuracy'])\n\n\n####\n# DenseNet201 MODEL :-\n####\n\nmod_DenseNet201 = DenseNet201(weights = \"imagenet\" , include_top = False , input_shape = (128 , 128 , 3))\n\nfor layer in mod_DenseNet201.layers:\n    layer.trainable = False\n\n\nz = mod_DenseNet201.output\nz = Flatten()(z)\nz = Dropout(0.35)(z)\nz = Dense(7 , activation = 'softmax')(z)\nmodel_DenseNet201 = Model(inputs = mod_DenseNet201.input , outputs = z)\n\nmodel_DenseNet201.compile(loss = tf.keras.losses.CategoricalCrossentropy() , \noptimizer = optimizers.Adam(learning_rate = 0.001) , \nmetrics = ['accuracy'])\n\n\n\n\n####\n# VGG16 MODEL :-\n####\n\nmod_VGG16 = VGG16(weights = \"imagenet\" , include_top = False , input_shape = (128 , 128 , 3))\n\nfor layer in mod_VGG16.layers:\n    layer.trainable = False\n\n\na = mod_VGG16.output\na = Flatten()(a)\na = Dropout(0.35)(a)\na = Dense(7 , activation = 'softmax')(a)\n\nmodel_VGG16 = Model(inputs = mod_VGG16.input , outputs = a)\n\nmodel_VGG16.compile(loss = tf.keras.losses.CategoricalCrossentropy() , \n                  optimizer = optimizers.Adam(learning_rate = 0.001) , \n                  metrics = ['accuracy'])\n\n\n\n\n####\n# NASNetMobile MODEL :-\n####\n\nmod_NASNET = NASNetMobile(weights = \"imagenet\" , include_top = False , input_shape = (128 , 128 , 3))\n\nfor layer in mod_NASNET.layers:\n    layer.trainable = False\n\n\nb = mod_NASNET.output\nb = Flatten()(b)\nb = Dropout(0.35)(b)\nb = Dense(7 , activation = 'softmax')(b)\n\nmodel_NASNet = Model(inputs = mod_NASNET.input , outputs = b)\n\nmodel_NASNet.compile(loss = tf.keras.losses.CategoricalCrossentropy() , \n                  optimizer = optimizers.Adam(learning_rate = 0.001) , \n                  metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def matplot_plotting(tr_acc , tr_loss , val_acc , val_loss ):\n    epochs = [i+1 for i in range(len(tr_acc))]\n\n    plt.figure(figsize=(20, 8))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, tr_loss, 'r', label='Train Loss')\n    plt.plot(epochs, val_loss, 'g', label='Valid Loss')\n    plt.title('Loss')\n    plt.legend()\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, tr_acc, 'r', label='Train Accuracy')\n    plt.plot(epochs, val_acc, 'g', label='Valid Accuracy')\n    plt.title('Accuracy')\n    plt.legend()\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model fitting of Inception_V3 and basic plotting :-\n\nwith tf.device('/device:GPU:0'):\n    history_InceptionV3 = model_InceptionV3.fit(x_train , y_train , \n                        epochs = 50 , batch_size = 16 , \n                        validation_data = (x_test , y_test) , \n                        verbose = 1)\n    \n\nacc_InceptionV3 = history_InceptionV3.history['accuracy']\nloss_InceptionV3 = history_InceptionV3.history['loss']\nval_acc_InceptionV3 = history_InceptionV3.history['val_accuracy']\nval_loss_InceptionV3 = history_InceptionV3.history['val_loss']\n\nmatplot_plotting(acc_InceptionV3 , loss_InceptionV3 , val_acc_InceptionV3 , val_loss_InceptionV3)\n\nmodel_InceptionV3.save('Inception_V3_HAM10K.h5')\n\nscore_InceptionV3 = model_InceptionV3.evaluate(x_test , y_test)\nprint(\"Test Accuracy InceptionV3 : \\t\" , score_InceptionV3[1]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model fitting of Xception and basic plotting :-\n\nwith tf.device('/device:GPU:0'):\n    history_Xception = model_Xception.fit(x_train , y_train , \n                        epochs = 50 , batch_size = 16 , \n                        validation_data = (x_test , y_test) , \n                        verbose = 1)\n    \n\nacc_Xception = history_Xception.history['accuracy']\nloss_Xception = history_Xception.history['loss']\nval_acc_Xception = history_Xception.history['val_accuracy']\nval_loss_Xception = history_Xception.history['val_loss']\n\nmatplot_plotting(acc_Xception , loss_Xception , val_acc_Xception , val_loss_Xception)\n\nmodel_Xception.save('Xception_HAM10K.h5')\n\nscore_Xception = model_Xception.evaluate(x_test , y_test)\nprint(\"Test Accuracy Xception : \\t\" , score_Xception[1]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model fitting of VGG16 and basic plotting :- \n\nwith tf.device('/device:GPU:0'):\n    history_VGG16 = model_VGG16.fit(x_train , y_train , \n                        epochs = 50 , batch_size = 16 , \n                        validation_data = (x_test , y_test) , \n                        verbose = 1)\n    \nacc_VGG16 = history_VGG16.history['accuracy']\nloss_VGG16 = history_VGG16.history['loss']\nval_acc_VGG16 = history_VGG16.history['val_accuracy']\nval_loss_VGG16 = history_VGG16.history['val_loss']\n\nmatplot_plotting(acc_VGG16 , loss_VGG16 , val_acc_VGG16 , val_loss_VGG16)\n\nmodel_VGG16.save('VGG16_HAM10K.h5')\n\nscore_VGG16 = model_VGG16.evaluate(x_test , y_test)\nprint(\"Test Accuracy InceptionV3 : \\t\" , score_VGG16[1]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model fitting of DenseNet and basic plotting :- \n\nwith tf.device('/device:GPU:0'):\n    history_DenseNet201 = model_DenseNet201.fit(x_train , y_train , \n                        epochs = 50 , batch_size = 16 , \n                        validation_data = (x_test , y_test) , \n                        verbose = 1)\n    \nacc_DenseNet201= history_DenseNet201.history['accuracy']\nloss_DenseNet201 = history_DenseNet201.history['loss']\nval_acc_DenseNet201 = history_DenseNet201.history['val_accuracy']\nval_loss_DenseNet201 = history_DenseNet201.history['val_loss']\n\nmatplot_plotting(acc_DenseNet201 , loss_DenseNet201 , val_acc_DenseNet201 , val_loss_DenseNet201)\n\nmodel_DenseNet201.save('DenseNet201_HAM10K.h5')\n\nscore_DenseNet201 = model_DenseNet201.evaluate(x_test , y_test) \nprint(\"Test Accuracy InceptionV3 : \\t\" , score_DenseNet201[1]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model fitting of NASNet and basic plotting :- \n\nwith tf.device('/device:GPU:0'):\n    history_NASNet = model_NASNet.fit(x_train , y_train , \n                        epochs = 50 , batch_size = 16 , \n                        validation_data = (x_test , y_test) , \n                        verbose = 1)\n    \nacc_NASNet = history_NASNet.history['accuracy']\nloss_NASNet = history_NASNet.history['loss']\nval_acc_NASNet = history_NASNet.history['val_accuracy']\nval_loss_NASNet = history_NASNet.history['val_loss']\n\nmatplot_plotting(acc_NASNet , loss_NASNet , val_acc_NASNet , val_loss_NASNet)\n\nmodel_NASNet.save('NASNet_HAM10K.h5')\n\nscore_NASNet = model_NASNet.evaluate(x_test , y_test)\nprint(\"Test Accuracy InceptionV3 : \\t\" , score_NASNet[1]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": False}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter( y= acc_InceptionV3, name=\"InceptionV3\")\n   \n)\n\nfig.add_trace(\n    go.Scatter( y= acc_Xception, name=\"Xception\")\n\n)\n\nfig.add_trace(\n    go.Scatter( y= acc_VGG16, name=\"VGG16\")\n    \n)\n\nfig.add_trace(\n    go.Scatter( y= acc_DenseNet201, name=\"DenseNet201\")\n    \n)\n\nfig.add_trace(\n    go.Scatter( y= acc_NASNet, name=\"NASNetMobile\")\n    \n)\n# Add figure title\nfig.update_layout(\n    title_text=\"Accuracy of all Models :\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Epoch\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Accuracy</b>\", secondary_y=False)\n\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = [i+1 for i in range(len(acc_InceptionV3))]\n\nplt.figure(figsize=(20, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs, acc_InceptionV3, 'r', label='Inception_V3')\nplt.plot(epochs, acc_Xception , 'g', label='Xception')\nplt.plot(epochs, acc_VGG16, 'b', label='VGG16')\nplt.plot(epochs, acc_DenseNet201, 'y', label='DenseNet201')\nplt.plot(epochs, acc_NASNet, 'c', label='NASNet')\nplt.title('Accuracy')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy %')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"/kaggle/working/","metadata":{},"execution_count":null,"outputs":[]}]}